{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from DrawtexModel import DrawTexModel\n",
    "from DrawtexDataset import DrawtexDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SZ = 128\n",
    "TEST_BATCH_SZ = 1000\n",
    "EPOCHS = 10\n",
    "LEARN_RATE = 0.01\n",
    "CLASS_CNT = 82\n",
    "\n",
    "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Dataloader setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrawTexModel(\n",
      "  (relu): ReLU()\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (lin1): Linear(in_features=30420, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=82, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_set = DrawtexDataset(transforms.ToTensor())\n",
    "TRAIN_SIZE = int(0.8 * len(data_set))\n",
    "TEST_SIZE = len(data_set) - TRAIN_SIZE\n",
    "train_set, test_set = torch.utils.data.random_split(data_set, [TRAIN_SIZE, TEST_SIZE])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=TRAIN_BATCH_SZ,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=TEST_BATCH_SZ,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "model = DrawTexModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, Step 128/2350, Loss 3.7226\n",
      "Epoch 0/10, Step 256/2350, Loss 3.6455\n",
      "Epoch 0/10, Step 384/2350, Loss 3.8262\n",
      "Epoch 0/10, Step 512/2350, Loss 3.7792\n",
      "Epoch 0/10, Step 640/2350, Loss 3.5864\n",
      "Epoch 0/10, Step 768/2350, Loss 3.8210\n",
      "Epoch 0/10, Step 896/2350, Loss 3.7410\n",
      "Epoch 0/10, Step 1024/2350, Loss 3.6869\n",
      "Epoch 0/10, Step 1152/2350, Loss 3.6522\n",
      "Epoch 0/10, Step 1280/2350, Loss 3.7225\n",
      "Epoch 0/10, Step 1408/2350, Loss 3.6468\n",
      "Epoch 0/10, Step 1536/2350, Loss 3.7665\n",
      "Epoch 0/10, Step 1664/2350, Loss 3.6963\n",
      "Epoch 0/10, Step 1792/2350, Loss 3.6438\n",
      "Epoch 0/10, Step 1920/2350, Loss 3.7650\n",
      "Epoch 0/10, Step 2048/2350, Loss 3.6921\n",
      "Epoch 0/10, Step 2176/2350, Loss 3.6139\n",
      "Epoch 0/10, Step 2304/2350, Loss 3.7207\n",
      "Epoch 1/10, Step 128/2350, Loss 3.7727\n",
      "Epoch 1/10, Step 256/2350, Loss 3.5014\n",
      "Epoch 1/10, Step 384/2350, Loss 3.6687\n",
      "Epoch 1/10, Step 512/2350, Loss 3.7680\n",
      "Epoch 1/10, Step 640/2350, Loss 3.5057\n",
      "Epoch 1/10, Step 768/2350, Loss 3.5137\n",
      "Epoch 1/10, Step 896/2350, Loss 3.6130\n",
      "Epoch 1/10, Step 1024/2350, Loss 3.5719\n",
      "Epoch 1/10, Step 1152/2350, Loss 3.7113\n",
      "Epoch 1/10, Step 1280/2350, Loss 3.7641\n",
      "Epoch 1/10, Step 1408/2350, Loss 3.7308\n",
      "Epoch 1/10, Step 1536/2350, Loss 3.6223\n",
      "Epoch 1/10, Step 1664/2350, Loss 3.7093\n",
      "Epoch 1/10, Step 1792/2350, Loss 3.6678\n",
      "Epoch 1/10, Step 1920/2350, Loss 3.4495\n",
      "Epoch 1/10, Step 2048/2350, Loss 3.8417\n",
      "Epoch 1/10, Step 2176/2350, Loss 3.7130\n",
      "Epoch 1/10, Step 2304/2350, Loss 3.6917\n",
      "Epoch 2/10, Step 128/2350, Loss 3.4957\n",
      "Epoch 2/10, Step 256/2350, Loss 3.6033\n",
      "Epoch 2/10, Step 384/2350, Loss 3.7822\n",
      "Epoch 2/10, Step 512/2350, Loss 3.6893\n",
      "Epoch 2/10, Step 640/2350, Loss 3.7724\n",
      "Epoch 2/10, Step 768/2350, Loss 3.5644\n",
      "Epoch 2/10, Step 896/2350, Loss 3.6078\n",
      "Epoch 2/10, Step 1024/2350, Loss 3.7041\n",
      "Epoch 2/10, Step 1152/2350, Loss 3.5432\n",
      "Epoch 2/10, Step 1280/2350, Loss 3.5193\n",
      "Epoch 2/10, Step 1408/2350, Loss 3.7612\n",
      "Epoch 2/10, Step 1536/2350, Loss 3.6144\n",
      "Epoch 2/10, Step 1664/2350, Loss 3.6938\n",
      "Epoch 2/10, Step 1792/2350, Loss 3.6931\n",
      "Epoch 2/10, Step 1920/2350, Loss 3.6583\n",
      "Epoch 2/10, Step 2048/2350, Loss 3.7152\n",
      "Epoch 2/10, Step 2176/2350, Loss 3.7650\n",
      "Epoch 2/10, Step 2304/2350, Loss 3.5992\n",
      "Epoch 3/10, Step 128/2350, Loss 3.6179\n",
      "Epoch 3/10, Step 256/2350, Loss 3.6086\n",
      "Epoch 3/10, Step 384/2350, Loss 3.7135\n",
      "Epoch 3/10, Step 512/2350, Loss 3.6361\n",
      "Epoch 3/10, Step 640/2350, Loss 3.5519\n",
      "Epoch 3/10, Step 768/2350, Loss 3.7312\n",
      "Epoch 3/10, Step 896/2350, Loss 3.6783\n",
      "Epoch 3/10, Step 1024/2350, Loss 3.5426\n",
      "Epoch 3/10, Step 1152/2350, Loss 3.8701\n",
      "Epoch 3/10, Step 1280/2350, Loss 3.4918\n",
      "Epoch 3/10, Step 1408/2350, Loss 3.5231\n",
      "Epoch 3/10, Step 1536/2350, Loss 3.7168\n",
      "Epoch 3/10, Step 1664/2350, Loss 3.8193\n",
      "Epoch 3/10, Step 1792/2350, Loss 3.7852\n",
      "Epoch 3/10, Step 1920/2350, Loss 3.6772\n",
      "Epoch 3/10, Step 2048/2350, Loss 3.5525\n",
      "Epoch 3/10, Step 2176/2350, Loss 3.4666\n",
      "Epoch 3/10, Step 2304/2350, Loss 3.7007\n",
      "Epoch 4/10, Step 128/2350, Loss 3.7522\n",
      "Epoch 4/10, Step 256/2350, Loss 3.5795\n",
      "Epoch 4/10, Step 384/2350, Loss 3.6808\n",
      "Epoch 4/10, Step 512/2350, Loss 3.5500\n",
      "Epoch 4/10, Step 640/2350, Loss 3.8700\n",
      "Epoch 4/10, Step 768/2350, Loss 3.7669\n",
      "Epoch 4/10, Step 896/2350, Loss 3.7705\n",
      "Epoch 4/10, Step 1024/2350, Loss 3.5686\n",
      "Epoch 4/10, Step 1152/2350, Loss 3.7214\n",
      "Epoch 4/10, Step 1280/2350, Loss 3.8943\n",
      "Epoch 4/10, Step 1408/2350, Loss 3.6950\n",
      "Epoch 4/10, Step 1536/2350, Loss 3.8864\n",
      "Epoch 4/10, Step 1664/2350, Loss 3.7193\n",
      "Epoch 4/10, Step 1792/2350, Loss 3.7583\n",
      "Epoch 4/10, Step 1920/2350, Loss 3.8108\n",
      "Epoch 4/10, Step 2048/2350, Loss 3.6948\n",
      "Epoch 4/10, Step 2176/2350, Loss 3.7475\n",
      "Epoch 4/10, Step 2304/2350, Loss 3.4321\n",
      "Epoch 5/10, Step 128/2350, Loss 3.8066\n",
      "Epoch 5/10, Step 256/2350, Loss 3.6015\n",
      "Epoch 5/10, Step 384/2350, Loss 3.6647\n",
      "Epoch 5/10, Step 512/2350, Loss 3.4828\n",
      "Epoch 5/10, Step 640/2350, Loss 3.8188\n",
      "Epoch 5/10, Step 768/2350, Loss 3.7927\n",
      "Epoch 5/10, Step 896/2350, Loss 3.7314\n",
      "Epoch 5/10, Step 1024/2350, Loss 3.5475\n",
      "Epoch 5/10, Step 1152/2350, Loss 3.8070\n",
      "Epoch 5/10, Step 1280/2350, Loss 3.7151\n",
      "Epoch 5/10, Step 1408/2350, Loss 3.5614\n",
      "Epoch 5/10, Step 1536/2350, Loss 3.7571\n",
      "Epoch 5/10, Step 1664/2350, Loss 3.6410\n",
      "Epoch 5/10, Step 1792/2350, Loss 3.5125\n",
      "Epoch 5/10, Step 1920/2350, Loss 3.6512\n",
      "Epoch 5/10, Step 2048/2350, Loss 3.5899\n",
      "Epoch 5/10, Step 2176/2350, Loss 3.5691\n",
      "Epoch 5/10, Step 2304/2350, Loss 3.5430\n",
      "Epoch 6/10, Step 128/2350, Loss 3.6885\n",
      "Epoch 6/10, Step 256/2350, Loss 3.8066\n",
      "Epoch 6/10, Step 384/2350, Loss 3.7501\n",
      "Epoch 6/10, Step 512/2350, Loss 3.7807\n",
      "Epoch 6/10, Step 640/2350, Loss 3.5798\n",
      "Epoch 6/10, Step 768/2350, Loss 3.7195\n",
      "Epoch 6/10, Step 896/2350, Loss 3.7418\n",
      "Epoch 6/10, Step 1024/2350, Loss 3.5823\n",
      "Epoch 6/10, Step 1152/2350, Loss 3.6205\n",
      "Epoch 6/10, Step 1280/2350, Loss 3.9333\n",
      "Epoch 6/10, Step 1408/2350, Loss 3.6755\n",
      "Epoch 6/10, Step 1536/2350, Loss 3.6029\n",
      "Epoch 6/10, Step 1664/2350, Loss 3.8945\n",
      "Epoch 6/10, Step 1792/2350, Loss 3.7251\n",
      "Epoch 6/10, Step 1920/2350, Loss 3.5504\n",
      "Epoch 6/10, Step 2048/2350, Loss 3.5973\n",
      "Epoch 6/10, Step 2176/2350, Loss 3.7059\n",
      "Epoch 6/10, Step 2304/2350, Loss 3.8496\n",
      "Epoch 7/10, Step 128/2350, Loss 3.7082\n",
      "Epoch 7/10, Step 256/2350, Loss 3.7153\n",
      "Epoch 7/10, Step 384/2350, Loss 3.6088\n",
      "Epoch 7/10, Step 512/2350, Loss 3.6560\n",
      "Epoch 7/10, Step 640/2350, Loss 3.5340\n",
      "Epoch 7/10, Step 768/2350, Loss 3.6771\n",
      "Epoch 7/10, Step 896/2350, Loss 3.6384\n",
      "Epoch 7/10, Step 1024/2350, Loss 3.5763\n",
      "Epoch 7/10, Step 1152/2350, Loss 3.8876\n",
      "Epoch 7/10, Step 1280/2350, Loss 3.4961\n",
      "Epoch 7/10, Step 1408/2350, Loss 3.7879\n",
      "Epoch 7/10, Step 1536/2350, Loss 3.5191\n",
      "Epoch 7/10, Step 1664/2350, Loss 3.6607\n",
      "Epoch 7/10, Step 1792/2350, Loss 3.7676\n",
      "Epoch 7/10, Step 1920/2350, Loss 3.7468\n",
      "Epoch 7/10, Step 2048/2350, Loss 3.7758\n",
      "Epoch 7/10, Step 2176/2350, Loss 3.7999\n",
      "Epoch 7/10, Step 2304/2350, Loss 3.7761\n",
      "Epoch 8/10, Step 128/2350, Loss 3.8322\n",
      "Epoch 8/10, Step 256/2350, Loss 3.8041\n",
      "Epoch 8/10, Step 384/2350, Loss 3.7033\n",
      "Epoch 8/10, Step 512/2350, Loss 3.5401\n",
      "Epoch 8/10, Step 640/2350, Loss 3.6933\n",
      "Epoch 8/10, Step 768/2350, Loss 3.8201\n",
      "Epoch 8/10, Step 896/2350, Loss 3.7180\n",
      "Epoch 8/10, Step 1024/2350, Loss 3.8930\n",
      "Epoch 8/10, Step 1152/2350, Loss 3.5425\n",
      "Epoch 8/10, Step 1280/2350, Loss 3.6702\n",
      "Epoch 8/10, Step 1408/2350, Loss 3.9333\n",
      "Epoch 8/10, Step 1536/2350, Loss 3.6775\n",
      "Epoch 8/10, Step 1664/2350, Loss 3.8845\n",
      "Epoch 8/10, Step 1792/2350, Loss 3.4756\n",
      "Epoch 8/10, Step 1920/2350, Loss 3.5560\n",
      "Epoch 8/10, Step 2048/2350, Loss 3.6487\n",
      "Epoch 8/10, Step 2176/2350, Loss 3.5259\n",
      "Epoch 8/10, Step 2304/2350, Loss 3.6384\n",
      "Epoch 9/10, Step 128/2350, Loss 3.6131\n",
      "Epoch 9/10, Step 256/2350, Loss 3.4571\n",
      "Epoch 9/10, Step 384/2350, Loss 3.6177\n",
      "Epoch 9/10, Step 512/2350, Loss 3.7219\n",
      "Epoch 9/10, Step 640/2350, Loss 3.7141\n",
      "Epoch 9/10, Step 768/2350, Loss 3.7366\n",
      "Epoch 9/10, Step 896/2350, Loss 3.7930\n",
      "Epoch 9/10, Step 1024/2350, Loss 3.6674\n",
      "Epoch 9/10, Step 1152/2350, Loss 3.6292\n",
      "Epoch 9/10, Step 1280/2350, Loss 3.7149\n",
      "Epoch 9/10, Step 1408/2350, Loss 3.5285\n",
      "Epoch 9/10, Step 1536/2350, Loss 3.5449\n",
      "Epoch 9/10, Step 1664/2350, Loss 3.6362\n",
      "Epoch 9/10, Step 1792/2350, Loss 3.6499\n",
      "Epoch 9/10, Step 1920/2350, Loss 3.6951\n",
      "Epoch 9/10, Step 2048/2350, Loss 3.7024\n",
      "Epoch 9/10, Step 2176/2350, Loss 3.5706\n",
      "Epoch 9/10, Step 2304/2350, Loss 3.6804\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARN_RATE)\n",
    "    steps = len(train_loader)\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (img, label) in enumerate(train_loader):\n",
    "            img: torch.Tensor = img.to(device, non_blocking=True)\n",
    "            label: torch.Tensor = label.to(device, non_blocking=True)\n",
    "            output = model(img)\n",
    "            loss: torch.Tensor = criterion(output, label).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % TRAIN_BATCH_SZ == 0:\n",
    "                print(f\"Epoch {epoch}/{EPOCHS}, Step {i + 1}/{steps}, Loss {loss.item():.4f}\")\n",
    "\n",
    "train()\n",
    "torch.save(model.state_dict(), \"./DrawTexModel.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 7.820998736618126%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "        img = img.to(device, non_blocking= True)\n",
    "        labels = labels.to(device, non_blocking= True)\n",
    "\n",
    "        output = model(img)\n",
    "        _, prediction = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    print(f\"Accuracy: {acc}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc82db2dc128658da88fa564359fe123ee9c6914f8c7963941acb47815200485"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
